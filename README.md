# Strategies for Robust Bust Image Classification

*Abstract*&mdash;In this work we evaluate the impact of digitally altered images on the performance of artificial neural networks. We explore factors that negatively affect the ability of an image classification model to produce consistent and accurate results. A model’s ability to classify is negatively influenced by alterations to images as a result of digital abnormalities or changes in the physical environment. The focus of this paper is to discover and replicate scenarios that modify the appearance of an image and evaluate them on state-of-the-art machine learning models. Our contributions present various training techniques that enhance a model’s ability to generalize and improve robustness against these alterations.

Find our paper [ **[here](ML_Robust_Report.pdf)** ]

`srs/`

- location of our neural network classifier code
- ml utilities for reading datasets, perturbing images, and visualizing results
- source of scripts to automate the training of various models

`notebooks/`

- experimental interactive python notebooks
- location of `notebooks/media` with all PDF visuals

`TeX/`

- LaTeX and BibTeX information to create our final paper

## Contributors

Jason D. Stock - stock@colostate.edu - [stockeh](https://github.com/stockeh)  
Andy A. Dolan - adolan5@colostate.edu - [adolan5](https://github.com/adolan5)  
Tom E. Cavey - tomcavey@colostate.edu - [tc30](https://github.com/tc30)
